# %%
import torch
from torch import optim
from torch.utils.data import Subset, Dataset, DataLoader, IterableDataset, TensorDataset
import torchvision.transforms as T
import torch.nn.functional as F
# from torchvision.datasets import CIFAR10
from torchvision.utils import save_image
from tqdm import tqdm
from datetime import datetime
from torch.amp import autocast
from denoising_diffusion_pytorch import Unet
from einops import rearrange, reduce, repeat
from ema_pytorch import EMA
from scipy.optimize import linear_sum_assignment
from accelerate import Accelerator
import math
import glob
from pathlib import Path
from random import random
from functools import partial
from collections import namedtuple
import os
import re
from typing import Literal
CWD = os.getcwd()

# Device stuff
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU Device:", torch.cuda.get_device_name(0))
    print("Number of GPUs:", torch.cuda.device_count())
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Remember to use {device} device from here on")
# print(os.chdir("../"))
# %cd /home/physics/phuqza/E9/DDPM-HL-LHC/
from DDPMLHC.config import *
from DDPMLHC.calculate_quantities import *
from DDPMLHC.data_loading import *
from DDPMLHC.generate_plots.overlaid_1d import *
from DDPMLHC.generate_plots.bmap import *
from DDPMLHC.generate_plots.histograms_1d import *
# from 

# def show_tensor_images(tensor_images, scale_factor=8):
#     to_pil = T.ToPILImage()
#     pil_images = [to_pil(image) for image in tensor_images]

#     for img in pil_images:
#         # Upscale the image
#         upscaled_img = img.resize(
#             (img.width * scale_factor, img.height * scale_factor), 
#             Image.NEAREST  # or Image.BOX for smoother results
#         )
#         display(upscaled_img)


# %%
# Base code for training generated by Claude 3.5. Since modified for our purposes.
# Changes from originally-generated response:
#  - Tracking of loss per epoch
# - Checkpoint saved in intervals rather than every epoch
# - Changed handling of range and loading when 0 epochs
## Custom reimplementation of Trainer from DDPM
## Avoid subclassing because we do not want to pass in literal files

def load_and_train(
    diffusion,
    dataloader,
    num_epochs,
    device,
    save_dir,
    lr=2e-4
):
    os.makedirs(save_dir, exist_ok=True)
    loss_array = []
    # Get last epoch number
    checkpoint_files = glob.glob(os.path.join(save_dir, 'checkpoint_epoch_*.pth'))
    last_epoch = 0
    if checkpoint_files:
        epoch_numbers = []
        for f in checkpoint_files:
            try:
                epoch_num = int(f.split('epoch_')[1].split('_loss')[0])
                epoch_numbers.append(epoch_num)
            except:
                continue
        last_epoch = max(epoch_numbers) if epoch_numbers else 0

    # Load checkpoint if exists
    if last_epoch > 0:
        checkpoint_pattern = os.path.join(save_dir, f'checkpoint_epoch_{last_epoch}_*.pth')
        checkpoint_file = glob.glob(checkpoint_pattern)[0]
        print(f"Loading checkpoint: {checkpoint_file}")
        checkpoint = torch.load(checkpoint_file, map_location=device)
        diffusion.load_state_dict(checkpoint['model_state_dict'])
    else:
        print("Starting fresh training")

    optimizer = optim.Adam(diffusion.parameters(), lr=lr)
    epoch_range = range(last_epoch, last_epoch + num_epochs)
    final_epoch = list(epoch_range)[-1] if len(list(epoch_range))> 0 else last_epoch

    for epoch in epoch_range:
        print(f"\nEpoch {epoch + 1}/{last_epoch + num_epochs}")
        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))

        running_loss = 0.0
        for i, images in progress_bar:
            images = images.to(device)
            optimizer.zero_grad()
            loss = diffusion(images)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            avg_loss = running_loss / (i + 1)
            progress_bar.set_postfix({'Loss': f'{avg_loss:.10f}'})
        loss_array.append(avg_loss)
        # Save checkpoint at the end of each epoch
        if epoch % 50 == 0 or epoch == final_epoch:
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}_loss_{avg_loss:.10f}.pth')
            torch.save({
                'epoch': epoch,
                'model_state_dict': diffusion.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_loss,
            }, checkpoint_path)
            print(f'Checkpoint saved: {checkpoint_path}')
    return loss_array


## Plot losses from available checkpoints

def get_losses_from_checkpoints(checkpoint_dir='./data/ML/second'):
    # Get absolute path to checkpoint directory
    checkpoint_pattern = os.path.join(checkpoint_dir, 'checkpoint_epoch_*_loss_*.pth')
    
    # Get all matching files
    files = glob.glob(checkpoint_pattern)
    losses = []
    pattern = r'loss_([\d.]+)\.pth'
    
    for file in files:
        match = re.search(pattern, file)
        if match:
            loss = float(match.group(1))
            losses.append(loss)
    
    return len(files), losses

# === Read in data
print("0 :: Loading original data")
tt = np.genfromtxt(
    TT_PATH, delimiter=",", encoding="utf-8", skip_header=1, max_rows=MAX_DATA_ROWS
)
pu = np.genfromtxt(
    PILEUP_PATH, delimiter=",", encoding="utf-8", skip_header=1, max_rows=MAX_DATA_ROWS
)
tt = EventSelector(tt)
pu = EventSelector(pu)
print("FINISHED loading data\n")

# Ground truth ttbar jets
NG_jet = NoisyGenerator(TTselector=tt, PUselector=pu, bins=BMAP_SQUARE_SIDE_LENGTH, mu=0)
# Second one to randomly generate and return pile-up events ONLY
NG_pu = NoisyGenerator(TTselector=tt, PUselector=pu, bins=BMAP_SQUARE_SIDE_LENGTH, mu=0, pu_only=True)

model = Unet(
    dim=UNET_DIMS,                  # Base dimensionality of feature maps
    dim_mults=(1, 2, 4, 8),  # Multipliers for feature dimensions at each level
    channels=1,              # E.g. 3 for RGB
).to(device)

# 
diffusion = PUDiffusion(
    model = model,
    puNG = NG_pu,
    jet_ng= NG_jet,
    image_size = BMAP_SQUARE_SIDE_LENGTH, 
    timesteps = TIMESTEPS,  # Number of diffusion steps
    objective = "pred_x0",
).to(device)

ng_for_dataloader = NGenForDataloader(NG_jet)
dataloader = DataLoader(ng_for_dataloader, batch_size=BATCH_SIZE, num_workers=2, shuffle = True, pin_memory = True)


def print_params(mode: Literal["TRAINING", "SAMPLING"],num_epochs=EPOCHS, mu=200):
    print("#############################")
    print("DIAGNOSTIC PARAMETERS")
    print("#############################")
    print(F"MODE: {mode}")
    print(f"Training Batch Size: {BATCH_SIZE}")
    print(f"mu: {mu}")
    print(f"Image Size/bins: {BMAP_SQUARE_SIDE_LENGTH}")
    print(f"UNET DIMS: {UNET_DIMS}")
    print(f"TOTAL EPOCHS: {num_epochs}")
    print(f"TOTAL DIFFUSION TIMESTEPS: {TIMESTEPS}")
    print(f"DEVICE: {device.type}")
    print("#############################")
    print("END DIAGNOSTIC PARAMETERS")
    print("#############################")
